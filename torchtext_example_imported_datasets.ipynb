{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torchtext.vocab import GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will import our own dataset: a personality prediction using mypersonlity dataset<br />\n",
    "which is unfortunately not available anymore (see their statement: https://sites.google.com/michalkosinski.com/mypersonality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prediction target, which are the big5 personaity scores\n",
    "y_AG = []\n",
    "y_CO = []\n",
    "y_ES = []\n",
    "y_EX = []\n",
    "y_IT = []\n",
    "with open(\"./wv_myp_observation.txt\", encoding=\"UTF-8\") as obFile:\n",
    "    for line in obFile:\n",
    "        info = line.strip().split(\",\")\n",
    "        y_AG.append([info[1]])\n",
    "        y_CO.append([info[2]])\n",
    "        y_ES.append([info[3]])\n",
    "        y_EX.append([info[4]])\n",
    "        y_IT.append([info[5]])\n",
    "y_AG = np.array(y_AG, dtype=\"float32\")\n",
    "y_CO = np.array(y_CO, dtype=\"float32\")\n",
    "y_ES = np.array(y_ES, dtype=\"float32\")\n",
    "y_EX = np.array(y_EX, dtype=\"float32\")\n",
    "y_IT = np.array(y_IT, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select target\n",
    "y = y_AG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the observation, which are Facebook posts\n",
    "dat = []\n",
    "with open(\"./wv_myp_allposts.txt\", encoding=\"UTF-8\") as obFile:\n",
    "    for line in obFile:\n",
    "        dat.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    last night was amazing not only did see propna...\n",
       "big5                                                 0.65\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allData = pd.concat((pd.DataFrame(dat), pd.DataFrame(y)), axis=1)\n",
    "allData.columns = ['text', 'big5']\n",
    "# Save the data to csv\n",
    "allData.to_csv(\"./allData_personality.csv\", sep=';', encoding='utf-8')\n",
    "# Print the first row\n",
    "allData.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   4   5   6   8   9  10  11  12  13  14  15  17  18  19  20\n",
      "  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  39\n",
      "  40  41  42  43  44  46  47  48  49  50  51  52  53  54  55  56  57  59\n",
      "  60  61  62  63  64  65  66  67  68  72  73  74  75  76  77  78  79  80\n",
      "  81  82  83  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100\n",
      " 101 102 103 104 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 134 135 136 137 138\n",
      " 139 141 142 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158\n",
      " 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 175 176 177\n",
      " 179 180 181 182 183 184 186 187 188 190 191 192 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 212 214 215 216 217 218\n",
      " 219 220 221 222 223 224 225 226 227 228 229 231 232 233 234 235 236 237\n",
      " 239 240 241 242 243 244 245 246 248]\n",
      "[  3   7  16  38  45  58  69  70  71  84  85 105 133 140 143 174 178 185\n",
      " 189 193 213 230 238 247 249]\n"
     ]
    }
   ],
   "source": [
    "# Do a 10-fold CV, here we only perform the first fold for simplicity\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "for train_index, test_index in kf.split(allData.index):\n",
    "    print(train_index)\n",
    "    print(test_index)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = allData.iloc[test_index]\n",
    "testData.to_csv(\"./testData_personality.csv\", sep=';', encoding='utf-8')\n",
    "trainData = allData.iloc[train_index]\n",
    "trainData.to_csv(\"./trainData_personality.csv\", sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset to train, test, and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0                                               text   big5\n",
      "0            3  thanks for all the birthday and christmas wish...  0.650\n",
      "1            7  laundry then packing then maybe sleeping ahhhh...  1.000\n",
      "2           16  bout sleep goodnight for tonight yoooo that ju...  0.820\n",
      "3           38  meh about open source because windows random e...  0.760\n",
      "4           45  just remembered seen naked guy running the sup...  0.620\n",
      "5           58  got his permit has the flu and under quarantin...  0.560\n",
      "6           69  thinks this the best day ever propname 30th bi...  0.750\n",
      "7           70  miss sister thank you everyone for the birthda...  0.634\n",
      "8           71  wondering work out actually working i'm kickin...  0.950\n",
      "9           84  its way early saturday heading work relaxing c...  0.800\n",
      "10          85  back reality some phone from san ramon called ...  0.800\n",
      "11         105  going flordia tomorrow vacation flordia for we...  0.500\n",
      "12         133  youtube rules honestly does green day sounds l...  0.780\n",
      "13         140  just got back from having great time orkney :-...  0.930\n",
      "14         143  r � � msaid   j � ulup � hi   ja   palju   s �...  0.690\n",
      "15         174  god house where the wild things are looks sooo...  0.760\n",
      "16         178  vegetarian delight can't wait for the x-box ch...  0.620\n",
      "17         185  never forget the truth only get better lying o...  0.660\n",
      "18         189  wants learn how make french macaroons turning ...  0.820\n",
      "19         193  quote from christian fundementalist idiot can ...  0.580\n",
      "20         213  this week kelsey gets lita star for her author...  0.650\n",
      "21         230  anyone want sing the bakery thursday night fre...  0.650\n",
      "22         238  why are clothes disappearing ewwwww grosssssss...  0.500\n",
      "23         247  i'm facebook noob has fever 102 going crazy fr...  0.750\n",
      "24         249  likes the sound thunder sleepy it's not even f...  0.630\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from csv\n",
    "df_train = pd.read_csv(\"./trainData_personality.csv\", encoding=\"UTF-8\", delimiter=\";\")\n",
    "\n",
    "# Set random seed and shuffle the data\n",
    "idx = np.arange(df_train.shape[0])\n",
    "np.random.seed(999)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "# Set the size of validation set\n",
    "VAL_RATIO = 0.15\n",
    "val_size = int(len(idx) * VAL_RATIO)\n",
    "\n",
    "# Split dataset to val and train dataset\n",
    "df_train.iloc[idx[val_size:], :].to_csv(\n",
    "    \"cache/dataset_train2.csv\", index=False)\n",
    "df_train.iloc[idx[:val_size], :].to_csv(\n",
    "    \"cache/dataset_val2.csv\", index=False)\n",
    "\n",
    "# Read the testing dataset\n",
    "df_test = pd.read_csv(\"./testData_personality.csv\", encoding=\"UTF-8\", delimiter=\";\")\n",
    "df_test.to_csv(\"cache/dataset_test2.csv\", index=False)\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify all fields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential = True: specify that the data is sequential\n",
    "# include_lengths = True: a list that store the length of each sentence will also be returned\n",
    "# lower = True: lowercase all words\n",
    "# tokenize = tokenizer: use out pre-defined tokenizer to tokenize the text. Default is text.split()\n",
    "# init_token = \"<SOS>\": a <SOS> will be added before the beginning of the text sequence\n",
    "# eos_token = \"<EOS>\": a <EOS> will be added after the end of the text sequence\n",
    "# We did not specify a parameter \"use_vocab\" cause it's already set to True, \n",
    "#        this parameter specify that all words in the text sequence will be converted into indexes\n",
    "#        and we can see the corresponding words to the indexes using TEXT.vocab.stoi\n",
    "TEXT = data.Field(sequential=True, include_lengths=True, lower=True, init_token='<SOS>', eos_token='<EOS>')\n",
    "\n",
    "# Label is our predict target, which is numeric \n",
    "# We specify the tensor type of this field shoud be float, not sequential, and shouldn't be convert to word indexes\n",
    "LABEL = data.Field(sequential=False, use_vocab=False, tensor_type=torch.FloatTensor)\n",
    "\n",
    "# Load the datasets\n",
    "# Discard the \"Unnamed: 0\" column by assigning it to None\n",
    "train,test, val = data.TabularDataset.splits(\n",
    "    path='cache/', format='csv', skip_header=True,\n",
    "    train='dataset_train2.csv', validation='dataset_val2.csv', test=\"dataset_test2.csv\",\n",
    "    fields=[\n",
    "        ('Unnamed: 0', None),\n",
    "        ('text', TEXT),\n",
    "        ('big5', LABEL)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we print out an Example in the training dataset.<br />\n",
    "You might notice that the data we get is a torchtext.data.example.Example object.<br />\n",
    "To print out the attribute of this object, use \".attribute\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<torchtext.data.example.Example object at 0x7f15c8587a58>\n",
      "['watching', 'gossip', 'girl', 'this', 'may', 'mean', \"i've\", 'failed', 'acquire', 'taste', 'died', 'wants', 'sleep', 'going', 'the', 'lone', 'star', 'ruby', 'conf', 'august', 'salvador', \"dali's\", 'distorted', 'clocks', 'were', 'inspired', 'melting', 'cheese', \"i'll\", 'never', 'eat', 'grilled', 'cheese', 'sandwich', 'the', 'same', 'way', 'again', 'find', 'funny', 'that', 'keep', 'clicking', 'unfamiliar', 'names', 'and', 'wondering', 'when', 'did', 'friend', 'this', 'person', 'and', 'until', 'realize', 'they', 'got', 'married', 'thinks', 'ice', 'the', 'best', 'puppy', 'treat', 'ever', 'puppy', 'training', 'classes', 'then', 'uga', 'football', 'weee', 'wine', 'cheese', \"teebow's\", 'tears', 'fun', 'enjoying', 'the', 'latest', 'imogen', 'heap', 'album', 'atlanta', 'spending', 'night', 'with', 'ibm', 'programmers', 'feels', 'like', 'chapter', 'out', 'microserfs', 'will', 'miss', 'stadler', 'heart', 'ruby', 'made', 'spicy', 'coconut', 'soup', 'mmm', 'back', 'austin', 'just', 'watched', 'back', 'the', 'future', 'for', 'the', 'first', 'time']\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "for num, batch in enumerate(train):\n",
    "    print(num)\n",
    "    print(batch)\n",
    "    print(batch.text)\n",
    "    print(batch.big5)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert words to indexes, we need to use the build_vocab() method from torchtext.data.Field object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the in-built word embedding model GloVe\n",
    "# You can use your own word embedding model using torchtext.vocab.Vectors\n",
    "TEXT.build_vocab(train, test, val, vectors=\"glove.6B.300d\", max_size=30000) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The converted word embeddings are stored under TEXT.vocab.vectors\n",
    "TEXT.vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The index-word correpondance is recorded in TEXT.vocab.stoi as a dictionary\n",
    "# We build a lookup dictionary for later use\n",
    "lookup = {b:a for a, b in TEXT.vocab.stoi.items()}\n",
    "lookup[30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 32: In each batch contains 32 instaces. \n",
    "#       It has been proved that training in a batch gives better performance than learn a single data at a time\n",
    "# device = torch.device(\"cuda\"): Use GPU. If you do not have a GPU enviornment, use torch.device(\"cpu\") instead\n",
    "# repeat = False: Do not repeat the iterator for multiple epochs\n",
    "# sort_key = lambda...: A key to use for sorting examples in order to batch together examples with similar lengths \n",
    "#       and minimize padding. The sort_key provided to the Iterator constructor overrides the sort_key attribute of  \n",
    "#       the Dataset, or defers to it if None\n",
    "train_iter, test_iter, val_iter = data.BucketIterator.splits(\n",
    "          (train, test, val), batch_size=32, device=torch.device(\"cuda\"), repeat=False, sort_key=lambda x: len(x.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we print out the data in train_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:\n",
      "\n",
      "[torchtext.data.batch.Batch of size 32]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 953x32 (GPU 0)]', '[torch.cuda.LongTensor of size 32 (GPU 0)]')\n",
      "\t[.big5]:[torch.cuda.FloatTensor of size 32 (GPU 0)] \n",
      "\n",
      "batch.big5:\n",
      "tensor([ 0.6000,  0.9500,  0.8000,  0.6000,  0.7400,  0.6500,  0.6000,\n",
      "         0.5600,  0.7900,  0.8100,  0.8000,  0.4600,  0.7700,  0.8700,\n",
      "         0.7700,  0.6600,  0.6000,  0.6500,  0.8760,  0.6700,  0.4000,\n",
      "         0.6000,  0.8500,  0.6700,  0.5000,  0.7000,  0.7500,  0.7500,\n",
      "         0.9100,  0.8300,  0.8600,  0.7900], device='cuda:0') \n",
      "\n",
      "batch.text[0]:\n",
      "tensor([[     2,      2,      2,  ...,      2,      2,      2],\n",
      "        [  5036,   1612,    125,  ...,    613,    158,     46],\n",
      "        [ 11954,    361,   1640,  ...,     21,     24,     31],\n",
      "        ...,\n",
      "        [     1,      1,      1,  ...,      1,      1,      1],\n",
      "        [     1,      1,      1,  ...,      1,      1,      1],\n",
      "        [     1,      1,      1,  ...,      1,      1,      1]], device='cuda:0') \n",
      "\n",
      "batch.text[0][0]:\n",
      "tensor([ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2], device='cuda:0') \n",
      "\n",
      "Fifth sentence: \n",
      "<SOS> cavs cavs rock the house <EOS> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> "
     ]
    }
   ],
   "source": [
    "for num, batch in enumerate(train_iter):\n",
    "    # batch is a torchtext.data.batch.Batch object\n",
    "    # In batch there are 32 instances\n",
    "    # The data in batch have two fields: text and label\n",
    "    # The text field contains the text index itself [len(longest sentence)x32] and \n",
    "    #          the length of each setence [32] in this batch (remember include_lengths=True?)\n",
    "    # The label field contains the prediction target [32]\n",
    "    print(\"batch:\")\n",
    "    print(batch, \"\\n\")\n",
    "    \n",
    "    # Print the label\n",
    "    print(\"batch.big5:\")\n",
    "    print(batch.big5, \"\\n\")\n",
    "    \n",
    "    # Print the first component of batch.text (the sequence of words)\n",
    "    print(\"batch.text[0]:\")\n",
    "    print(batch.text[0], \"\\n\")\n",
    "    \n",
    "    # Print the first element in batch.text[0], which is all first words in all the sentences\n",
    "    # You may notice that the results are all 2\n",
    "    # That's because we use <SOS> to represent the beginning of a sentence\n",
    "    # Going back to TEXT.vocab.stoi you can find that the index of <SOS> is 2\n",
    "    print(\"batch.text[0][0]:\")\n",
    "    print(batch.text[0][0], \"\\n\")\n",
    "    \n",
    "    # Print the actual content fifth sentence in this batch\n",
    "    # Noted that we use the lookup dictionary to recover the word index to word\n",
    "    print(\"Fifth sentence: \")\n",
    "    for i in range(batch.text[0].size()[0]):\n",
    "        print(lookup[batch.text[0][i].tolist()[5]], end=\" \")\n",
    "    # You might find that torchtext automatically add <PAD>s after <EOS> to make all sentence \n",
    "    #           having identical length in this batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, copy the word embeddings to torch.nn.Embedding object\n",
    "Then you can use this embed for your RNN model! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The second parameter(300) is the number of dimension of your embedding model\n",
    "# padding_idx = 1: specify the <PAD>'s index is 1\n",
    "# max_norm = 1: If given, will renormalize the embeddings to always have a norm lesser than the given number\n",
    "embed = nn.Embedding(len(TEXT.vocab), 300, padding_idx=1, max_norm=1)\n",
    "\n",
    "# Copy the word vectors from dataset to nn.Embedding object\n",
    "embed.weight.data.copy_(TEXT.vocab.vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
